{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29c990e-5dd8-41a0-b570-313c7222e0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d31026698643b5b1544c17f3be59a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55eb1ae8-239a-4fe1-be8b-5b1056996af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "775d8aac-37a8-4e41-9822-c403e4b8b9dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoModelForCausalLM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# \"bigscience/bloom-7b1\",\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/datadrive/llm/tmp/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# load_in_4bit=True,\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m, cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/datadrive/llm/tmp/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForCausalLM' is not defined"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    # \"bigscience/bloom-7b1\",\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    cache_dir=\"/datadrive/llm/tmp/\",\n",
    "    # load_in_4bit=True,\n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", cache_dir=\"/datadrive/llm/tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bf361ef-b885-4bd9-a005-ea39630c8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea3165a-cd79-4a8e-abc1-8620501b6f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: I ate 1 apple out of 67 apples. How many apples are remaining?\n",
      "Answer: 66 apples.<\\end>\n",
      "Question: I ate 45 apple out of 101 apples. How many apples are remaining?\n",
      "Answer: 56 apples.<\\end>\n",
      "Question: I ate 76 apples out of 345 apples. How many apples are remaining?\n",
      "Answer: 26\n"
     ]
    }
   ],
   "source": [
    "prompt = '''Question: I ate 1 apple out of 67 apples. How many apples are remaining?\n",
    "Answer: 66 apples.<\\end>\n",
    "Question: I ate 45 apple out of 101 apples. How many apples are remaining?\n",
    "Answer: 56 apples.<\\end>\n",
    "Question: I ate 76 apples out of 345 apples. How many apples are remaining?\n",
    "Answer:'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163b0689-2dfa-4a1f-84c9-3711a000428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python code to loop from 1 to 10 and print the numbers is:\n",
      "\n",
      "\\begin{code}\n",
      "for i in range(1, 11):\n",
      "    print(i)\n",
      "\\end{code}\n",
      "\n",
      "I want to write a code that will loop from 1 to 100\n"
     ]
    }
   ],
   "source": [
    "prompt='''python code to loop from 1 to 10 and print the numbers is:'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8abdabd-4330-44d8-a381-289da1301cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translation of sentence \"i want to eat\" in french is \"je veux manger\"\n",
      "I want to eat.\n",
      "I want to eat a lot.\n",
      "I want to eat a lot of food.\n",
      "I want to eat a lot of food.\n",
      "I want to eat a lot of food\n"
     ]
    }
   ],
   "source": [
    "prompt='''translation of sentence \"i want to eat\" in french is'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3d5e42-0d91-4f1b-8028-2688f02e3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translation of sentence \"i want to eat\" in hindi is \"मैं खाना चाहता हूं\"\n",
      "I want to eat.\n",
      "मैं खाना चाहता हूं\n",
      "I want to eat\n"
     ]
    }
   ],
   "source": [
    "prompt='''translation of sentence \"i want to eat\" in hindi is'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6afebab1-f9c9-4cbc-a81a-edb55c5b3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part of speech tag for the sentence \"मैं खाना चाहता हूं\" is?\n",
      "\n",
      "I am learning NLTK and I am trying to tag the sentence \"मैं खाना चाहता हूं\" as a verb.\n",
      "\n",
      "I am using the following code:\n",
      "\n",
      "\\begin{code}\n",
      "from nltk.tag import pos_tag\n",
      "\n",
      "sentence = \"मैं खाना चाहता हूं\"\n",
      "\n",
      "pos_tag(sent\n"
     ]
    }
   ],
   "source": [
    "prompt='''part of speech tag for the sentence \"मैं खाना चाहता हूं\" is'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be3a46d-2ed0-42f0-97e4-4410b83317c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give part of speech tag for sentences:\n",
      "sentence: I am running\n",
      "tags: I/PR am/V running/V\n",
      "sentence: train is standing\n",
      "tags: train/N is/V standing/V\n",
      "sentence: he gave a gift to his teacher\n",
      "tags: he/PR gave/V a gift/N to/P his/P teacher/N\n",
      "sentence: I am going to the park\n",
      "tags: I/PR am/V going/V to/P the park/N\n",
      "sentence: I am going to the park with my friends\n",
      "tags: I/PR am/V going/V to/P the park/N with/P my/P friends/N\n",
      "sentence: I am going to the park with\n"
     ]
    }
   ],
   "source": [
    "prompt='''Give part of speech tag for sentences:\n",
    "sentence: I am running\n",
    "tags: I/PR am/V running/V\n",
    "sentence: train is standing\n",
    "tags: train/N is/V standing/V\n",
    "sentence: he gave a gift to his teacher\n",
    "tags:'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386cf624-4432-4f0a-85ce-6f2bc98564c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given Hanuman is a subject, the subject complements could be -\n",
      "\n",
      "\\begin{code}\n",
      "Hanuman is a monkey.\n",
      "Hanuman is a monkey and a hero.\n",
      "Hanuman is a monkey and a hero and a subject.\n",
      "\\end{code}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt='''given Hanuman is a subject, the subject complements could be -'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a888009-a702-4a99-8c65-84389ff3e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the triple extracted from the sentence \"I ate mango\" is: 1. I ate 2. mango 3.\n",
      "the triple extracted from the sentence \"I ate mango\" is: 1. I ate 2. mango 3. ate mango\n",
      "The triple\n"
     ]
    }
   ],
   "source": [
    "prompt='''the triple extracted from the sentence \"I ate mango\" is: '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0920b625-2b10-4300-8afb-e92efae99782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence \"मैंने आम खाया\" is: मैं आम खाया\n",
      "\n",
      "I ate the common food.\n",
      "\n",
      "the relationship triple extracted from the sentence \"मैंने आम खाया\" is: मैं\n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence \"मैंने आम खाया\" is: '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c915fa36-704e-4c12-96e7-7e3b76d69e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence: \n",
      "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
      "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
      "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
      "वह टोपी पहनता है ->  (वह) (पहनता है) (टोपी)\n",
      "वह कपड़े पहनता है ->  (वह) (पहनता\n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence: \n",
    "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
    "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
    "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
    "वह टोपी पहनता है -> '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663e6a43-ceb8-485a-95ff-938521e13af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence: \n",
      "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
      "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
      "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
      "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
      "राम ने रावण को मारा ->  (राम) (ने) (मारा) (रावण)\n",
      "राम ने रावण को मारा है ->  (राम\n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence: \n",
    "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
    "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
    "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
    "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
    "राम ने रावण को मारा -> '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9c85b6-c9ef-4ffe-b829-f3f4f117edfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence: \n",
      "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
      "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
      "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
      "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
      "रावण को राम ने मारा ->  (राम) (मारा) (रावण)\n",
      "राम ने रावण को मारा ->  (राम) (मारा)\n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence: \n",
    "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
    "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
    "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
    "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
    "रावण को राम ने मारा -> '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f81fa235-835f-4c29-b608-51b960915a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence: \n",
      "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
      "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
      "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
      "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
      "तिवारी ने संवाददाता को बुलाया -> (तिवारी ने) (बुलाया) (संवाददाता को)\n",
      "बस्तर को पहाड़ियों ने सजाया है -> (पहाड़ियों ने) (सजाया है) (बस्तर को)\n",
      "राम ने रावण को मारा ->  (राम ने) (मारा) (रावण को)\n",
      "राम ने रावण को मारा ->  (राम \n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence: \n",
    "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
    "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
    "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
    "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
    "तिवारी ने संवाददाता को बुलाया -> (तिवारी ने) (बुलाया) (संवाददाता को)\n",
    "बस्तर को पहाड़ियों ने सजाया है -> (पहाड़ियों ने) (सजाया है) (बस्तर को)\n",
    "राम ने रावण को मारा -> '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82fc7c10-0f72-41e6-a654-fb329f7a5741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence: \n",
      "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
      "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
      "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
      "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
      "तिवारी ने संवाददाता को बुलाया -> (तिवारी ने) (बुलाया) (संवाददाता को)\n",
      "बस्तर को पहाड़ियों ने सजाया है -> (पहाड़ियों ने) (सजाया है) (बस्तर को)\n",
      "रावण को राम ने मारा ->  (राम ने) (मारा) (रावण को)\n",
      "राम ने रावण को मारा ->  (राम \n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence: \n",
    "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
    "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
    "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
    "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
    "तिवारी ने संवाददाता को बुलाया -> (तिवारी ने) (बुलाया) (संवाददाता को)\n",
    "बस्तर को पहाड़ियों ने सजाया है -> (पहाड़ियों ने) (सजाया है) (बस्तर को)\n",
    "रावण को राम ने मारा -> '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d6e243-af88-44ed-bb94-586171dfe62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence: \n",
      "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
      "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
      "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
      "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
      "तिवारी ने संवाददाता को बुलाया -> (तिवारी ने) (बुलाया) (संवाददाता को)\n",
      "बस्तर को पहाड़ियों ने सजाया है -> (पहाड़ियों ने) (सजाया है) (बस्तर को)\n",
      "पुलिस ने इस मामले में श्रीसंथ समेत 14 लोगों को गिरफ्तार किया है ->  (पुलिस ने) (गिरफ्तार किया है) (श्रीसंथ समेत 14 लोगों)\n",
      "The relationship triple extracted from the sentence: मैंने आम खाया ->  (म\n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence: \n",
    "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
    "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
    "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
    "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
    "तिवारी ने संवाददाता को बुलाया -> (तिवारी ने) (बुलाया) (संवाददाता को)\n",
    "बस्तर को पहाड़ियों ने सजाया है -> (पहाड़ियों ने) (सजाया है) (बस्तर को)\n",
    "पुलिस ने इस मामले में श्रीसंथ समेत 14 लोगों को गिरफ्तार किया है -> '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7480ea50-4131-4418-88e9-5272bb6e5947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence: \n",
      "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
      "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
      "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
      "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
      "राम ने रावण को मारा -> (राम ने) (मारा) (रावण को)\n",
      "रवि ने यातायात रोक दिया ->  (रवि ने) (रोक दिया) (यातायात)\n",
      "राम ने रावण को मारा -> (र\n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence: \n",
    "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
    "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
    "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
    "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
    "राम ने रावण को मारा -> (राम ने) (मारा) (रावण को)\n",
    "रवि ने यातायात रोक दिया -> '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80cf5e65-daed-4bb2-8d73-48bc93b2a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relationship triple extracted from the sentence: \n",
      "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
      "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
      "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
      "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
      "राम ने रावण को मारा -> (राम ने) (मारा) (रावण को)\n",
      "रवि ने यातायात रोक दिया -> (रवि ने) (रोक दिया) (यातायात)\n",
      "जॉन ने पॉल को उपहार दिया ->  (जॉन ने) (उपहार दिया) (पॉल)\n",
      "The first sentence is a simple sentence. The second sentence is a compound sentence. The\n"
     ]
    }
   ],
   "source": [
    "prompt='''the relationship triple extracted from the sentence: \n",
    "मैंने आम खाया ->  (मैंने) (खाया) (आम)\n",
    "मैंने व्याख्यान दिया -> (मैंने) (दिया) (व्याख्यान)\n",
    "वह कपड़े सिलता है -> (वह) (सिलता है) (कपड़े)\n",
    "वह टोपी पहनता है -> (वह) (पहनता है) (टोपी)\n",
    "राम ने रावण को मारा -> (राम ने) (मारा) (रावण को)\n",
    "रवि ने यातायात रोक दिया -> (रवि ने) (रोक दिया) (यातायात)\n",
    "जॉन ने पॉल को उपहार दिया -> '''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da274cc3-fa0a-4614-a5c4-e3b8a2bff719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to get a high-quality and qualitative essay, you should choose a reliable essay writing service. Unterscheidung von essay und abhandlung.\n",
      "The best essay writing service that gives you peace of mind and the best grades in\n"
     ]
    }
   ],
   "source": [
    "prompt='''If you want'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012ebb9-09e3-427f-921c-5c217f28eccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c528645-866c-4d25-96f5-08ee18a10c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fb980-7bb7-485c-93af-945ea15aaeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0f000-e8fd-466f-808d-cb8a18312523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e838506-01b7-43e4-bac4-a369a6384493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec04d8d-1f49-4008-a38c-7a2a209e70e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af01800-de63-4049-8c53-24badbd92ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
